{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tNDMg4jlgrfi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cargar embeddings y datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3A334T5bIXPD",
        "outputId": "74b0d7bb-b2bb-4340-dd85-fe1229fd15d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(4287, 768)\n"
          ]
        }
      ],
      "source": [
        "bert_embeddings = np.load(\"../../Datos/goodreads_bert_embeddings.npy\")  # shape: (num_items, embedding_dim)\n",
        "#bert_embeddings_large = np.load(\"goodreads_bert_large_embeddings.npy\")\n",
        "num_items, embedding_dim = bert_embeddings.shape\n",
        "#num_items, embedding_dim_large = bert_embeddings.shape\n",
        "\n",
        "print(bert_embeddings.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Crear matriz de similiradad entre embeddings de libros."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "P1Z49Mb-hvqe",
        "outputId": "3ec4b9b4-c380-4cd8-e823-db8fd4d7b513"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>4277</th>\n",
              "      <th>4278</th>\n",
              "      <th>4279</th>\n",
              "      <th>4280</th>\n",
              "      <th>4281</th>\n",
              "      <th>4282</th>\n",
              "      <th>4283</th>\n",
              "      <th>4284</th>\n",
              "      <th>4285</th>\n",
              "      <th>4286</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.673440</td>\n",
              "      <td>0.719119</td>\n",
              "      <td>0.764368</td>\n",
              "      <td>0.625514</td>\n",
              "      <td>0.653403</td>\n",
              "      <td>0.667970</td>\n",
              "      <td>0.746485</td>\n",
              "      <td>0.365827</td>\n",
              "      <td>0.778021</td>\n",
              "      <td>...</td>\n",
              "      <td>0.397503</td>\n",
              "      <td>0.543145</td>\n",
              "      <td>0.540901</td>\n",
              "      <td>0.755875</td>\n",
              "      <td>0.744101</td>\n",
              "      <td>0.626962</td>\n",
              "      <td>0.708529</td>\n",
              "      <td>0.717081</td>\n",
              "      <td>0.700909</td>\n",
              "      <td>0.717331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.673440</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.734144</td>\n",
              "      <td>0.676823</td>\n",
              "      <td>0.584083</td>\n",
              "      <td>0.681751</td>\n",
              "      <td>0.678472</td>\n",
              "      <td>0.818591</td>\n",
              "      <td>0.305292</td>\n",
              "      <td>0.753320</td>\n",
              "      <td>...</td>\n",
              "      <td>0.328485</td>\n",
              "      <td>0.502907</td>\n",
              "      <td>0.427954</td>\n",
              "      <td>0.732703</td>\n",
              "      <td>0.696381</td>\n",
              "      <td>0.539709</td>\n",
              "      <td>0.798792</td>\n",
              "      <td>0.728484</td>\n",
              "      <td>0.643580</td>\n",
              "      <td>0.654849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.719119</td>\n",
              "      <td>0.734144</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.791913</td>\n",
              "      <td>0.696762</td>\n",
              "      <td>0.760271</td>\n",
              "      <td>0.755001</td>\n",
              "      <td>0.834920</td>\n",
              "      <td>0.422391</td>\n",
              "      <td>0.775918</td>\n",
              "      <td>...</td>\n",
              "      <td>0.422090</td>\n",
              "      <td>0.613360</td>\n",
              "      <td>0.550323</td>\n",
              "      <td>0.777666</td>\n",
              "      <td>0.744185</td>\n",
              "      <td>0.652123</td>\n",
              "      <td>0.725647</td>\n",
              "      <td>0.753039</td>\n",
              "      <td>0.713980</td>\n",
              "      <td>0.772262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.764368</td>\n",
              "      <td>0.676823</td>\n",
              "      <td>0.791913</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.713837</td>\n",
              "      <td>0.798685</td>\n",
              "      <td>0.744020</td>\n",
              "      <td>0.781990</td>\n",
              "      <td>0.382928</td>\n",
              "      <td>0.733460</td>\n",
              "      <td>...</td>\n",
              "      <td>0.380449</td>\n",
              "      <td>0.556346</td>\n",
              "      <td>0.570946</td>\n",
              "      <td>0.814491</td>\n",
              "      <td>0.701956</td>\n",
              "      <td>0.643730</td>\n",
              "      <td>0.674895</td>\n",
              "      <td>0.639143</td>\n",
              "      <td>0.675953</td>\n",
              "      <td>0.768697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.625514</td>\n",
              "      <td>0.584083</td>\n",
              "      <td>0.696762</td>\n",
              "      <td>0.713837</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.656778</td>\n",
              "      <td>0.684132</td>\n",
              "      <td>0.681233</td>\n",
              "      <td>0.411072</td>\n",
              "      <td>0.590116</td>\n",
              "      <td>...</td>\n",
              "      <td>0.447254</td>\n",
              "      <td>0.538642</td>\n",
              "      <td>0.494055</td>\n",
              "      <td>0.700218</td>\n",
              "      <td>0.563526</td>\n",
              "      <td>0.562335</td>\n",
              "      <td>0.598830</td>\n",
              "      <td>0.552857</td>\n",
              "      <td>0.704690</td>\n",
              "      <td>0.624733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4282</th>\n",
              "      <td>0.626962</td>\n",
              "      <td>0.539709</td>\n",
              "      <td>0.652123</td>\n",
              "      <td>0.643730</td>\n",
              "      <td>0.562335</td>\n",
              "      <td>0.643197</td>\n",
              "      <td>0.631860</td>\n",
              "      <td>0.644756</td>\n",
              "      <td>0.382428</td>\n",
              "      <td>0.613364</td>\n",
              "      <td>...</td>\n",
              "      <td>0.493581</td>\n",
              "      <td>0.713897</td>\n",
              "      <td>0.709345</td>\n",
              "      <td>0.655685</td>\n",
              "      <td>0.630458</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.591962</td>\n",
              "      <td>0.627551</td>\n",
              "      <td>0.596663</td>\n",
              "      <td>0.651534</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4283</th>\n",
              "      <td>0.708529</td>\n",
              "      <td>0.798792</td>\n",
              "      <td>0.725647</td>\n",
              "      <td>0.674895</td>\n",
              "      <td>0.598830</td>\n",
              "      <td>0.714164</td>\n",
              "      <td>0.650955</td>\n",
              "      <td>0.707901</td>\n",
              "      <td>0.354210</td>\n",
              "      <td>0.728052</td>\n",
              "      <td>...</td>\n",
              "      <td>0.399784</td>\n",
              "      <td>0.568883</td>\n",
              "      <td>0.538148</td>\n",
              "      <td>0.669548</td>\n",
              "      <td>0.740572</td>\n",
              "      <td>0.591962</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.804356</td>\n",
              "      <td>0.704511</td>\n",
              "      <td>0.707331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4284</th>\n",
              "      <td>0.717081</td>\n",
              "      <td>0.728484</td>\n",
              "      <td>0.753039</td>\n",
              "      <td>0.639143</td>\n",
              "      <td>0.552857</td>\n",
              "      <td>0.664127</td>\n",
              "      <td>0.692349</td>\n",
              "      <td>0.720891</td>\n",
              "      <td>0.365877</td>\n",
              "      <td>0.752773</td>\n",
              "      <td>...</td>\n",
              "      <td>0.383236</td>\n",
              "      <td>0.584921</td>\n",
              "      <td>0.542766</td>\n",
              "      <td>0.668235</td>\n",
              "      <td>0.781792</td>\n",
              "      <td>0.627551</td>\n",
              "      <td>0.804356</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.660810</td>\n",
              "      <td>0.738834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4285</th>\n",
              "      <td>0.700909</td>\n",
              "      <td>0.643580</td>\n",
              "      <td>0.713980</td>\n",
              "      <td>0.675953</td>\n",
              "      <td>0.704690</td>\n",
              "      <td>0.657830</td>\n",
              "      <td>0.681003</td>\n",
              "      <td>0.771596</td>\n",
              "      <td>0.418413</td>\n",
              "      <td>0.720591</td>\n",
              "      <td>...</td>\n",
              "      <td>0.483352</td>\n",
              "      <td>0.589077</td>\n",
              "      <td>0.498116</td>\n",
              "      <td>0.694656</td>\n",
              "      <td>0.709605</td>\n",
              "      <td>0.596663</td>\n",
              "      <td>0.704511</td>\n",
              "      <td>0.660810</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.625742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4286</th>\n",
              "      <td>0.717331</td>\n",
              "      <td>0.654849</td>\n",
              "      <td>0.772262</td>\n",
              "      <td>0.768697</td>\n",
              "      <td>0.624733</td>\n",
              "      <td>0.786735</td>\n",
              "      <td>0.644369</td>\n",
              "      <td>0.759687</td>\n",
              "      <td>0.355999</td>\n",
              "      <td>0.738206</td>\n",
              "      <td>...</td>\n",
              "      <td>0.358510</td>\n",
              "      <td>0.559181</td>\n",
              "      <td>0.606123</td>\n",
              "      <td>0.750660</td>\n",
              "      <td>0.700229</td>\n",
              "      <td>0.651534</td>\n",
              "      <td>0.707331</td>\n",
              "      <td>0.738834</td>\n",
              "      <td>0.625742</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4287 rows × 4287 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1         2         3         4         5         6     \\\n",
              "0     1.000000  0.673440  0.719119  0.764368  0.625514  0.653403  0.667970   \n",
              "1     0.673440  1.000000  0.734144  0.676823  0.584083  0.681751  0.678472   \n",
              "2     0.719119  0.734144  1.000000  0.791913  0.696762  0.760271  0.755001   \n",
              "3     0.764368  0.676823  0.791913  1.000000  0.713837  0.798685  0.744020   \n",
              "4     0.625514  0.584083  0.696762  0.713837  1.000000  0.656778  0.684132   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "4282  0.626962  0.539709  0.652123  0.643730  0.562335  0.643197  0.631860   \n",
              "4283  0.708529  0.798792  0.725647  0.674895  0.598830  0.714164  0.650955   \n",
              "4284  0.717081  0.728484  0.753039  0.639143  0.552857  0.664127  0.692349   \n",
              "4285  0.700909  0.643580  0.713980  0.675953  0.704690  0.657830  0.681003   \n",
              "4286  0.717331  0.654849  0.772262  0.768697  0.624733  0.786735  0.644369   \n",
              "\n",
              "          7         8         9     ...      4277      4278      4279  \\\n",
              "0     0.746485  0.365827  0.778021  ...  0.397503  0.543145  0.540901   \n",
              "1     0.818591  0.305292  0.753320  ...  0.328485  0.502907  0.427954   \n",
              "2     0.834920  0.422391  0.775918  ...  0.422090  0.613360  0.550323   \n",
              "3     0.781990  0.382928  0.733460  ...  0.380449  0.556346  0.570946   \n",
              "4     0.681233  0.411072  0.590116  ...  0.447254  0.538642  0.494055   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "4282  0.644756  0.382428  0.613364  ...  0.493581  0.713897  0.709345   \n",
              "4283  0.707901  0.354210  0.728052  ...  0.399784  0.568883  0.538148   \n",
              "4284  0.720891  0.365877  0.752773  ...  0.383236  0.584921  0.542766   \n",
              "4285  0.771596  0.418413  0.720591  ...  0.483352  0.589077  0.498116   \n",
              "4286  0.759687  0.355999  0.738206  ...  0.358510  0.559181  0.606123   \n",
              "\n",
              "          4280      4281      4282      4283      4284      4285      4286  \n",
              "0     0.755875  0.744101  0.626962  0.708529  0.717081  0.700909  0.717331  \n",
              "1     0.732703  0.696381  0.539709  0.798792  0.728484  0.643580  0.654849  \n",
              "2     0.777666  0.744185  0.652123  0.725647  0.753039  0.713980  0.772262  \n",
              "3     0.814491  0.701956  0.643730  0.674895  0.639143  0.675953  0.768697  \n",
              "4     0.700218  0.563526  0.562335  0.598830  0.552857  0.704690  0.624733  \n",
              "...        ...       ...       ...       ...       ...       ...       ...  \n",
              "4282  0.655685  0.630458  1.000000  0.591962  0.627551  0.596663  0.651534  \n",
              "4283  0.669548  0.740572  0.591962  1.000000  0.804356  0.704511  0.707331  \n",
              "4284  0.668235  0.781792  0.627551  0.804356  1.000000  0.660810  0.738834  \n",
              "4285  0.694656  0.709605  0.596663  0.704511  0.660810  1.000000  0.625742  \n",
              "4286  0.750660  0.700229  0.651534  0.707331  0.738834  0.625742  1.000000  \n",
              "\n",
              "[4287 rows x 4287 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# computa similaridad coseno entre los features de las imagenes\n",
        "cosSimilarities = cosine_similarity(bert_embeddings)\n",
        "index = np.arange(num_items)\n",
        "# guardamos los resultados en un dataframe\n",
        "cos_similarities_df = pd.DataFrame(cosSimilarities, columns=index, index=index)\n",
        "cos_similarities_df #.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "IkeaYzMvJuis"
      },
      "outputs": [],
      "source": [
        "df_books = pd.read_csv('../../Datos/books.csv', sep=',')\n",
        "# dict index 2 book id and vice-versa for recommendation\n",
        "idx2bookid = {i: id_ for i, id_ in enumerate(df_books.book_id)}\n",
        "bookid2idx = {id_:i for i, id_ in enumerate(df_books.book_id)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "yIfCSGAbJ-WM"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "with open(\"../../Datos/goodreads_past_interactions.json\", \"r\") as f:\n",
        "    user_interactions = json.load(f)\n",
        "\n",
        "idx2userid = {i: id_ for i, id_ in enumerate(user_interactions.keys())}\n",
        "userid2idx = {id_:i for i, id_ in enumerate(user_interactions.keys())}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "UYALNwd9Jbt4"
      },
      "outputs": [],
      "source": [
        "with open(\"../../Datos/goodreads_test_interactions.json\", \"r\") as f:\n",
        "    user_interactions_test = json.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Crear matrices sparse."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(52821, 4287)\n"
          ]
        }
      ],
      "source": [
        "from scipy.sparse import coo_matrix\n",
        "max_user_id = []\n",
        "max_item_id = []\n",
        "\n",
        "for user_id, book_ids in user_interactions.items():\n",
        "    for book_id in book_ids:\n",
        "        u_id = userid2idx[user_id]\n",
        "        b_id = bookid2idx[book_id]\n",
        "        max_user_id.append(int(u_id))\n",
        "        max_item_id.append(int(b_id))\n",
        "\n",
        "max_user_id = max(max_user_id)\n",
        "max_item_id = max(max_item_id)\n",
        "\n",
        "rows_test = []\n",
        "cols_test = []\n",
        "data_test = []\n",
        "\n",
        "for user_id, book_ids in user_interactions_test.items():\n",
        "    for book_id in book_ids:\n",
        "        u_id = userid2idx[user_id]\n",
        "        b_id = bookid2idx[book_id]\n",
        "        rows_test.append(int(u_id))\n",
        "        cols_test.append(int(b_id))\n",
        "        data_test.append(1)\n",
        "\n",
        "max_user_id = max([max_user_id] + rows_test)\n",
        "max_item_id = max([max_item_id] + cols_test)\n",
        "\n",
        "test_users = list(set(rows_test))\n",
        "\n",
        "# Crear matriz sparse\n",
        "user_item_matrix_test = coo_matrix((data_test, (rows_test, cols_test)), shape=(max_user_id + 1, max_item_id + 1))\n",
        "print(user_item_matrix_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def recommend(given_index, sim_matrix, nb_closest_books=10):\n",
        "\n",
        "    closest_imgs = sim_matrix[given_index].sort_values(ascending=False)[1:nb_closest_books+1].index\n",
        "    closest_imgs_scores = sim_matrix[given_index].sort_values(ascending=False)[1:nb_closest_books+1]\n",
        "\n",
        "    closest_imgs = closest_imgs.to_numpy()\n",
        "    closest_imgs_scores = closest_imgs_scores.to_numpy()\n",
        "    recs = [(img, score) for img, score in zip(closest_imgs, closest_imgs_scores)]\n",
        "\n",
        "    return recs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generar recomendaciones\n",
        "\n",
        "Para cada usuario, generar recomendaciones basadas en similitud de embeddings para su historial de libros."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUOhR0WaJoSe",
        "outputId": "096a7747-bd87-44b8-eb60-d7b07b3c408b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[228, 2328, 1678, 2231, 2713, 879, 3070, 3791, 520, 1875], [2718, 2676, 2418, 3658, 3307, 704, 3092, 1643, 293, 4265]]\n"
          ]
        }
      ],
      "source": [
        "recs = []\n",
        "counter = 0\n",
        "nb_closest_books = 10  # number of closest books to recommend\n",
        "\n",
        "for user in test_users:\n",
        "  user = idx2userid[user]\n",
        "  past_interactions = user_interactions[user]\n",
        "  user_recs = []\n",
        "  rec_tuples = set()\n",
        "  # obtener libros similares para cada libro\n",
        "  # con el que el usuario ha interactuado anteriormente\n",
        "  for book_id in past_interactions:\n",
        "    book_idx = bookid2idx[book_id]\n",
        "    results = set(recommend(book_idx, cos_similarities_df, nb_closest_books)) # para sacar duplicados\n",
        "    rec_tuples = rec_tuples.union(results)\n",
        "  rec_tuples = list(rec_tuples)\n",
        "  rec_tuples.sort(key=lambda x: x[1], reverse=True) # ordenar por similaridad\n",
        "  rec_tuples = rec_tuples[:nb_closest_books] # quedarse con las primeras n\n",
        "  for rec in rec_tuples:\n",
        "    book_id = df_books.book_id[rec[0]]\n",
        "    user_recs.append(bookid2idx[book_id])\n",
        "  recs.append(user_recs)\n",
        "  counter += 1\n",
        "  #if counter > 20:\n",
        "  #  break\n",
        "\n",
        "print(recs[:2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generar recomendaciones con PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>4277</th>\n",
              "      <th>4278</th>\n",
              "      <th>4279</th>\n",
              "      <th>4280</th>\n",
              "      <th>4281</th>\n",
              "      <th>4282</th>\n",
              "      <th>4283</th>\n",
              "      <th>4284</th>\n",
              "      <th>4285</th>\n",
              "      <th>4286</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.102909</td>\n",
              "      <td>0.021346</td>\n",
              "      <td>0.313489</td>\n",
              "      <td>0.061513</td>\n",
              "      <td>-0.171128</td>\n",
              "      <td>0.034359</td>\n",
              "      <td>0.106179</td>\n",
              "      <td>0.005857</td>\n",
              "      <td>0.353691</td>\n",
              "      <td>...</td>\n",
              "      <td>0.015657</td>\n",
              "      <td>-0.055729</td>\n",
              "      <td>-0.017706</td>\n",
              "      <td>0.261829</td>\n",
              "      <td>0.240035</td>\n",
              "      <td>0.027720</td>\n",
              "      <td>0.000643</td>\n",
              "      <td>0.068118</td>\n",
              "      <td>0.148212</td>\n",
              "      <td>0.105708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.102909</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.117357</td>\n",
              "      <td>-0.162405</td>\n",
              "      <td>-0.200487</td>\n",
              "      <td>-0.220154</td>\n",
              "      <td>-0.083577</td>\n",
              "      <td>0.300937</td>\n",
              "      <td>-0.239672</td>\n",
              "      <td>0.104152</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.225985</td>\n",
              "      <td>-0.288894</td>\n",
              "      <td>-0.437211</td>\n",
              "      <td>-0.014535</td>\n",
              "      <td>-0.079330</td>\n",
              "      <td>-0.373035</td>\n",
              "      <td>0.218987</td>\n",
              "      <td>-0.034010</td>\n",
              "      <td>-0.207130</td>\n",
              "      <td>-0.348607</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.021346</td>\n",
              "      <td>-0.117357</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.252192</td>\n",
              "      <td>0.185201</td>\n",
              "      <td>0.054877</td>\n",
              "      <td>0.200475</td>\n",
              "      <td>0.252013</td>\n",
              "      <td>0.039919</td>\n",
              "      <td>0.103864</td>\n",
              "      <td>...</td>\n",
              "      <td>0.012878</td>\n",
              "      <td>-0.020943</td>\n",
              "      <td>-0.124700</td>\n",
              "      <td>0.135417</td>\n",
              "      <td>0.030961</td>\n",
              "      <td>-0.053059</td>\n",
              "      <td>-0.219085</td>\n",
              "      <td>0.032328</td>\n",
              "      <td>0.017895</td>\n",
              "      <td>0.140942</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.313489</td>\n",
              "      <td>-0.162405</td>\n",
              "      <td>0.252192</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.309194</td>\n",
              "      <td>0.380990</td>\n",
              "      <td>0.238233</td>\n",
              "      <td>0.218081</td>\n",
              "      <td>0.013551</td>\n",
              "      <td>0.092788</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.047537</td>\n",
              "      <td>-0.077849</td>\n",
              "      <td>0.053254</td>\n",
              "      <td>0.457397</td>\n",
              "      <td>0.019333</td>\n",
              "      <td>0.037603</td>\n",
              "      <td>-0.241394</td>\n",
              "      <td>-0.275948</td>\n",
              "      <td>-0.010620</td>\n",
              "      <td>0.245576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.061513</td>\n",
              "      <td>-0.200487</td>\n",
              "      <td>0.185201</td>\n",
              "      <td>0.309194</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.070255</td>\n",
              "      <td>0.277520</td>\n",
              "      <td>0.102652</td>\n",
              "      <td>0.215331</td>\n",
              "      <td>-0.163571</td>\n",
              "      <td>...</td>\n",
              "      <td>0.218572</td>\n",
              "      <td>0.053924</td>\n",
              "      <td>-0.035964</td>\n",
              "      <td>0.237541</td>\n",
              "      <td>-0.191744</td>\n",
              "      <td>-0.008941</td>\n",
              "      <td>-0.178926</td>\n",
              "      <td>-0.277769</td>\n",
              "      <td>0.366952</td>\n",
              "      <td>-0.004407</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 4287 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       0         1         2         3         4         5         6     \\\n",
              "0  1.000000 -0.102909  0.021346  0.313489  0.061513 -0.171128  0.034359   \n",
              "1 -0.102909  1.000000 -0.117357 -0.162405 -0.200487 -0.220154 -0.083577   \n",
              "2  0.021346 -0.117357  1.000000  0.252192  0.185201  0.054877  0.200475   \n",
              "3  0.313489 -0.162405  0.252192  1.000000  0.309194  0.380990  0.238233   \n",
              "4  0.061513 -0.200487  0.185201  0.309194  1.000000  0.070255  0.277520   \n",
              "\n",
              "       7         8         9     ...      4277      4278      4279      4280  \\\n",
              "0  0.106179  0.005857  0.353691  ...  0.015657 -0.055729 -0.017706  0.261829   \n",
              "1  0.300937 -0.239672  0.104152  ... -0.225985 -0.288894 -0.437211 -0.014535   \n",
              "2  0.252013  0.039919  0.103864  ...  0.012878 -0.020943 -0.124700  0.135417   \n",
              "3  0.218081  0.013551  0.092788  ... -0.047537 -0.077849  0.053254  0.457397   \n",
              "4  0.102652  0.215331 -0.163571  ...  0.218572  0.053924 -0.035964  0.237541   \n",
              "\n",
              "       4281      4282      4283      4284      4285      4286  \n",
              "0  0.240035  0.027720  0.000643  0.068118  0.148212  0.105708  \n",
              "1 -0.079330 -0.373035  0.218987 -0.034010 -0.207130 -0.348607  \n",
              "2  0.030961 -0.053059 -0.219085  0.032328  0.017895  0.140942  \n",
              "3  0.019333  0.037603 -0.241394 -0.275948 -0.010620  0.245576  \n",
              "4 -0.191744 -0.008941 -0.178926 -0.277769  0.366952 -0.004407  \n",
              "\n",
              "[5 rows x 4287 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=100)\n",
        "reduced_embeddings = pca.fit_transform(bert_embeddings)\n",
        "# computa similaridad coseno entre los features de las imagenes\n",
        "pca_cosSimilarities = cosine_similarity(reduced_embeddings)\n",
        "index = np.arange(num_items)\n",
        "# guardamos los resultados en un dataframe\n",
        "pca_cos_similarities_df = pd.DataFrame(pca_cosSimilarities, columns=index, index=index)\n",
        "pca_cos_similarities_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[879, 2743, 3544, 4279, 2737, 439, 784, 75, 228, 1678], [2718, 2676, 2418, 3658, 3307, 3092, 1643, 704, 293, 2465]]\n"
          ]
        }
      ],
      "source": [
        "recs_pca = []\n",
        "counter = 0\n",
        "nb_closest_books = 10  # number of closest books to recommend\n",
        "\n",
        "for user in test_users:\n",
        "  user = idx2userid[user]\n",
        "  past_interactions = user_interactions[user]\n",
        "  user_recs = []\n",
        "  rec_tuples = set()\n",
        "  # obtener libros similares para cada libro\n",
        "  # con el que el usuario ha interactuado anteriormente\n",
        "  for book_id in past_interactions:\n",
        "    book_idx = bookid2idx[book_id]\n",
        "    results = set(recommend(book_idx, pca_cos_similarities_df, nb_closest_books)) # para sacar duplicados\n",
        "    rec_tuples = rec_tuples.union(results)\n",
        "  rec_tuples = list(rec_tuples)\n",
        "  rec_tuples.sort(key=lambda x: x[1], reverse=True) # ordenar por similaridad\n",
        "  rec_tuples = rec_tuples[:nb_closest_books] # quedarse con las primeras n\n",
        "  for rec in rec_tuples:\n",
        "    book_id = df_books.book_id[rec[0]]\n",
        "    user_recs.append(bookid2idx[book_id])\n",
        "  recs_pca.append(user_recs)\n",
        "  counter += 1\n",
        "  #if counter > 20:\n",
        "  #  break\n",
        "\n",
        "print(recs_pca[:2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluar recomendaciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "t30rH5bFOiK4"
      },
      "outputs": [],
      "source": [
        "# funcion para calcular metricas dadas las recomendaciones ya hechas\n",
        "def recs_ranking_metrics_at_k(recommendations, test_user_items, K=10):\n",
        "\n",
        "    # Ensure matrices are in CSR format\n",
        "    #train_user_items = train_user_items.tocsr()\n",
        "    test_user_items = test_user_items.tocsr()\n",
        "\n",
        "    num_users, num_items = test_user_items.shape\n",
        "    relevant = 0\n",
        "    total_precision_div = 0\n",
        "    total_map = 0\n",
        "    total_ndcg = 0\n",
        "    total_auc = 0\n",
        "    total_users = 0\n",
        "\n",
        "    # Compute cumulative gain for NDCG normalization\n",
        "    cg = 1.0 / np.log2(np.arange(2, K + 2))  # Discount factor\n",
        "    cg_sum = np.cumsum(cg)  # Ideal DCG normalization\n",
        "\n",
        "    # Get users with at least one item in the test set\n",
        "    users_with_test_data = np.where(np.diff(test_user_items.indptr) > 0)[0]\n",
        "\n",
        "    # Progress bar\n",
        "    #progress = tqdm.tqdm(total=len(users_with_test_data), disable=not show_progress)\n",
        "\n",
        "    batch_size = 1000\n",
        "    start_idx = 0\n",
        "\n",
        "    while start_idx < len(users_with_test_data):\n",
        "        batch_users = users_with_test_data[start_idx:start_idx + batch_size]\n",
        "        #recommended_items, _ = model.recommend(batch_users, train_user_items[batch_users], N=K)\n",
        "        recommended_items = recommendations[start_idx:start_idx + batch_size]\n",
        "        start_idx += batch_size\n",
        "\n",
        "        for user_idx, user_id in enumerate(batch_users):\n",
        "            test_items = set(test_user_items.indices[test_user_items.indptr[user_id]:test_user_items.indptr[user_id + 1]])\n",
        "\n",
        "            if not test_items:\n",
        "                continue  # Skip users without test data\n",
        "\n",
        "            num_relevant = len(test_items)\n",
        "            total_precision_div += min(K, num_relevant)\n",
        "\n",
        "            ap = 0\n",
        "            hit_count = 0\n",
        "            auc = 0\n",
        "            idcg = cg_sum[min(K, num_relevant) - 1]  # Ideal Discounted Cumulative Gain (IDCG)\n",
        "            num_negative = num_items - num_relevant\n",
        "\n",
        "            for rank, item in enumerate(recommended_items[user_idx]):\n",
        "                if item in test_items:\n",
        "                    relevant += 1\n",
        "                    hit_count += 1\n",
        "                    ap += hit_count / (rank + 1)\n",
        "                    total_ndcg += cg[rank] / idcg\n",
        "                else:\n",
        "                    auc += hit_count  # Accumulate hits for AUC calculation\n",
        "\n",
        "            auc += ((hit_count + num_relevant) / 2.0) * (num_negative - (K - hit_count))\n",
        "            total_map += ap / min(K, num_relevant)\n",
        "            total_auc += auc / (num_relevant * num_negative)\n",
        "            total_users += 1\n",
        "\n",
        "        #progress.update(len(batch_users))\n",
        "\n",
        "    #progress.close()\n",
        "\n",
        "    # Compute final metrics\n",
        "    precision = relevant / total_precision_div if total_precision_div > 0 else 0\n",
        "    mean_ap = total_map / total_users if total_users > 0 else 0\n",
        "    mean_ndcg = total_ndcg / total_users if total_users > 0 else 0\n",
        "    mean_auc = total_auc / total_users if total_users > 0 else 0\n",
        "\n",
        "    return {\n",
        "        \"precision\": precision,\n",
        "        \"map\": mean_ap,\n",
        "        \"ndcg\": mean_ndcg,\n",
        "        \"auc\": mean_auc\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'precision': 0.007, 'map': 0.00307420634920635, 'ndcg': 0.00606241562353928, 'auc': 0.502338555061959}\n",
            "{'precision': 0.002, 'map': 0.0009, 'ndcg': 0.0022400556151517554, 'auc': 0.4998342296001867}\n"
          ]
        }
      ],
      "source": [
        "print(recs_ranking_metrics_at_k(recs, user_item_matrix_test, K=10))\n",
        "print(recs_ranking_metrics_at_k(recs_pca, user_item_matrix_test, K=10))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
